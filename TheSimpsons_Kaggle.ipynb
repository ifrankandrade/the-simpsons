{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpsons Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df_nation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nation.rename(columns={'levels':'1000-level'}, inplace=True)\n",
    "conditions_frequency = [(df_nation['levels'] <= 3),\n",
    "             (df_nation['levels'] == 4),\n",
    "             (df_nation['levels'] >= 5) & (df_nation['levels']<= 14)]\n",
    "values_frequency = ['1-3', '4', '5-14']\n",
    "df_nation['levels_frequency'] = np.select(conditions_frequency, values_frequency)\n",
    "\n",
    "conditions_coverage = [(df_nation['levels']<=14),\n",
    "                        (df_nation['levels']>=15) & (df_nation['levels']<=25),\n",
    "                      (df_nation['levels']>=26)]\n",
    "values_coverage = [df_nation['levels'], 15, df_nation['levels']]\n",
    "\n",
    "df_nation['levels_coverage'] = np.select(conditions_coverage, values_coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/scrapping/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (4,5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_simpsons = pd.read_csv('simpsons_script_lines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleaning import clean_transcripts\n",
    "\n",
    "round1 = lambda x: clean_transcripts(x)\n",
    "\n",
    "df_simpsons['spoken_words'] = df_simpsons['spoken_words'].astype(str).apply(round1)\n",
    "df_simpsons['spoken_words'] = df_simpsons['spoken_words'].apply(lambda x:x+' ')\n",
    "not_str = df_simpsons[df_simpsons['character_id'].str.contains('[^\\d]', na=False)].index.values\n",
    "df_simpsons.drop(not_str, axis=0, inplace=True)\n",
    "df_simpsons.dropna(subset=['character_id'], inplace=True)\n",
    "df_simpsons['character_id'] = df_simpsons['character_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simpsons characteres by total number of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_character_text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Homer Simpson</th>\n",
       "      <td>29842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marge Simpson</th>\n",
       "      <td>14159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bart Simpson</th>\n",
       "      <td>13777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lisa Simpson</th>\n",
       "      <td>11502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C. Montgomery Burns</th>\n",
       "      <td>3172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moe Szyslak</th>\n",
       "      <td>2864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seymour Skinner</th>\n",
       "      <td>2443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ned Flanders</th>\n",
       "      <td>2145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grampa Simpson</th>\n",
       "      <td>1886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milhouse Van Houten</th>\n",
       "      <td>1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chief Wiggum</th>\n",
       "      <td>1836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Krusty the Clown</th>\n",
       "      <td>1772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nelson Muntz</th>\n",
       "      <td>1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lenny Leonard</th>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apu Nahasapeemapetilon</th>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waylon Smithers</th>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kent Brockman</th>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carl Carlson</th>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edna Krabappel-Flanders</th>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Julius Hibbert</th>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         raw_text\n",
       "raw_character_text               \n",
       "Homer Simpson               29842\n",
       "Marge Simpson               14159\n",
       "Bart Simpson                13777\n",
       "Lisa Simpson                11502\n",
       "C. Montgomery Burns          3172\n",
       "Moe Szyslak                  2864\n",
       "Seymour Skinner              2443\n",
       "Ned Flanders                 2145\n",
       "Grampa Simpson               1886\n",
       "Milhouse Van Houten          1862\n",
       "Chief Wiggum                 1836\n",
       "Krusty the Clown             1772\n",
       "Nelson Muntz                 1174\n",
       "Lenny Leonard                1166\n",
       "Apu Nahasapeemapetilon       1006\n",
       "Waylon Smithers              1001\n",
       "Kent Brockman                 894\n",
       "Carl Carlson                  883\n",
       "Edna Krabappel-Flanders       745\n",
       "Dr. Julius Hibbert            693"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simpsons_lines = df_simpsons.groupby('raw_character_text').count().sort_values(by=['raw_text'], ascending=False)[['raw_text']][:20]\n",
    "df_simpsons_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_id</th>\n",
       "      <th>spoken_words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>never thrown a party what about that big bash ...</td>\n",
       "      <td>288596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>lisa tell your father homer you are not allowe...</td>\n",
       "      <td>134192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>victory party under the slide hey thanks for y...</td>\n",
       "      <td>117468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>where s mr bergstrom that life is worth living...</td>\n",
       "      <td>106054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>must turn over got to greet dignitaries absolu...</td>\n",
       "      <td>38266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>238</td>\n",
       "      <td>that s right michael jackson    the thriller h...</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6</td>\n",
       "      <td>ew a bug nan it s your turn jimbo hm someone s...</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2065</td>\n",
       "      <td>hey guys c amon shut up oh yes believe me my g...</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2304</td>\n",
       "      <td>i am an orphan from capitol city and those who...</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>785</td>\n",
       "      <td>thank you tonight i d like to try something a ...</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    character_id                                       spoken_words  tokens\n",
       "0              2  never thrown a party what about that big bash ...  288596\n",
       "1              1  lisa tell your father homer you are not allowe...  134192\n",
       "2              8  victory party under the slide hey thanks for y...  117468\n",
       "3              9  where s mr bergstrom that life is worth living...  106054\n",
       "4             15  must turn over got to greet dignitaries absolu...   38266\n",
       "..           ...                                                ...     ...\n",
       "95           238  that s right michael jackson    the thriller h...     777\n",
       "96             6  ew a bug nan it s your turn jimbo hm someone s...     769\n",
       "97          2065  hey guys c amon shut up oh yes believe me my g...     765\n",
       "98          2304  i am an orphan from capitol city and those who...     737\n",
       "99           785  thank you tonight i d like to try something a ...     736\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simpsons_analysis = df_simpsons[['character_id', 'spoken_words']].groupby('character_id').sum()\n",
    "df_simpsons_analysis = df_simpsons_analysis.reset_index()\n",
    "df_simpsons_analysis.sort_values(by='character_id')\n",
    "df_simpsons_analysis['tokens'] = df_simpsons_analysis['spoken_words'].apply(lambda x:len(x.split()))\n",
    "#Top 100 characters\n",
    "df_simpsons_analysis = df_simpsons_analysis.sort_values('tokens', ascending=False)[:100]\n",
    "df_simpsons_analysis = df_simpsons_analysis.reset_index(drop=True)\n",
    "df_simpsons_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>character_id</th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index0</td>\n",
       "      <td>2</td>\n",
       "      <td>Homer Simpson</td>\n",
       "      <td>288596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>index1</td>\n",
       "      <td>1</td>\n",
       "      <td>Marge Simpson</td>\n",
       "      <td>134192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>index2</td>\n",
       "      <td>8</td>\n",
       "      <td>Bart Simpson</td>\n",
       "      <td>117468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>index3</td>\n",
       "      <td>9</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>106054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>index4</td>\n",
       "      <td>15</td>\n",
       "      <td>C. Montgomery Burns</td>\n",
       "      <td>38266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>index95</td>\n",
       "      <td>238</td>\n",
       "      <td>Marty</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>index96</td>\n",
       "      <td>6</td>\n",
       "      <td>Dewey Largo</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>index97</td>\n",
       "      <td>2065</td>\n",
       "      <td>Drederick Tatum</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>index98</td>\n",
       "      <td>2304</td>\n",
       "      <td>Armin</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>index99</td>\n",
       "      <td>785</td>\n",
       "      <td>Lurleen Lumpkin</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  character_id   raw_character_text  tokens\n",
       "0    index0             2        Homer Simpson  288596\n",
       "1    index1             1        Marge Simpson  134192\n",
       "2    index2             8         Bart Simpson  117468\n",
       "3    index3             9         Lisa Simpson  106054\n",
       "4    index4            15  C. Montgomery Burns   38266\n",
       "..      ...           ...                  ...     ...\n",
       "95  index95           238                Marty     777\n",
       "96  index96             6          Dewey Largo     769\n",
       "97  index97          2065      Drederick Tatum     765\n",
       "98  index98          2304                Armin     737\n",
       "99  index99           785      Lurleen Lumpkin     736\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_character = df_simpsons[['character_id', 'raw_character_text']]\n",
    "df_character = df_character.drop_duplicates('character_id').reset_index(drop=True).sort_values('character_id')\n",
    "df_character = pd.merge(df_simpsons_analysis, df_character, on='character_id')[['character_id', 'raw_character_text', 'tokens']][:100]\n",
    "df_character = df_character.reset_index()\n",
    "df_character['index'] = df_character['index'].apply(lambda x:'index'+str(x))\n",
    "df_character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "import scipy.sparse\n",
    "cv_transcripts = CountVectorizer()#only misleading words excluded for the analysis\n",
    "cv_matrix_transcripts = cv_transcripts.fit_transform(df_simpsons_analysis['spoken_words'])\n",
    "df_dtm = pd.DataFrame.sparse.from_spmatrix(cv_matrix_transcripts, index=df_simpsons_analysis.index,\n",
    "                                           columns=cv_transcripts.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtm = df_dtm.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#behaviour\n",
    "def get_frames(indices, dtm, thousand_level=None): #, thousand_level ['4'], ['5-14']\n",
    "    \"\"\"1. The df_dtm gives the number of times a word (all_forms) shows up in an episode/movie\n",
    "       2. Then its joined to get the level and base_forms of each word\n",
    "       3. The final df has the words counted for each episode so it can be seen base_forms repetition in the final df\"\"\"\n",
    "    frames = []\n",
    "    for index in indices:\n",
    "        df_count_words = dtm[[index]].loc[dtm[index]!=0]\n",
    "        df_count_words = df_count_words.reset_index()\n",
    "        df_count_words.rename(columns={\"index\": \"all_forms\", index: \"count\"}, inplace=True)\n",
    "\n",
    "        df_count_words_level = pd.merge(df_count_words, df_nation[['base_forms', 'all_forms',\n",
    "                                'levels_frequency', 'levels', 'levels_coverage']], how='left', on='all_forms')\n",
    "        df_count_words_level = df_count_words_level.dropna() ##INNER JOIN\n",
    "        if thousand_level is not None:\n",
    "            df_count_words_level = df_count_words_level[df_count_words_level['levels_frequency'].isin(thousand_level)]\n",
    "        frames.append(df_count_words_level)\n",
    "    df_count_words_level = pd.concat(frames)\n",
    "    return df_count_words_level\n",
    "\n",
    "def get_count(df_movie_nation):\n",
    "    \"\"\"Grouping by base_forms of word and summing their number of encounters\n",
    "    Note: the 'count' column type in most cases is 'SPARSE NUMPY INT'. Then I have to use the \n",
    "    first 2 lines in the 'try' block to get 'int'. However, for some reason some columns after\n",
    "    concatenating (in def get_frames)  are 'int'values. They go straigt to the 'except' block \"\"\"\n",
    "    try:\n",
    "        int_value = [i.item() for i in df_movie_nation['count']]\n",
    "        df_movie_nation['count'] = int_value\n",
    "        df_count = df_movie_nation.groupby(by=['base_forms']).sum().reset_index()\n",
    "        df_count = df_count.rename(columns={'count':'base_forms_encounters'})\n",
    "        df_count = df_count.sort_values(by=['base_forms_encounters'], ascending=False)\n",
    "    except:\n",
    "        df_count = df_movie_nation.groupby(by=['base_forms']).sum().reset_index()\n",
    "        df_count = df_count.rename(columns={'count':'base_forms_encounters'})\n",
    "        df_count = df_count.sort_values(by=['base_forms_encounters'], ascending=False)\n",
    "    return df_count\n",
    "\n",
    "def get_statistics(df_movie_nation, df_count):\n",
    "    \"\"\"We merge and only get the root encounters to have a clean df when presenting data\"\"\"\n",
    "    df_movie_nation.drop_duplicates(['base_forms'], inplace=True)\n",
    "    df_movie_nation.drop(['all_forms','count'], axis=1, inplace=True)#Dropping columns from the df created in get_frames\n",
    "    df_movie_nation = pd.merge(df_movie_nation, df_count, on='base_forms')[['base_forms_encounters']]\n",
    "\n",
    "    conditions = [\n",
    "    (df_movie_nation['base_forms_encounters'] == 1),\n",
    "    (df_movie_nation['base_forms_encounters'] == 2),\n",
    "    (df_movie_nation['base_forms_encounters'] >= 3) & (df_movie_nation['base_forms_encounters'] <= 4),\n",
    "    (df_movie_nation['base_forms_encounters'] >= 5) & (df_movie_nation['base_forms_encounters'] <= 7),\n",
    "    (df_movie_nation['base_forms_encounters'] >= 8) & (df_movie_nation['base_forms_encounters'] <= 9),\n",
    "    (df_movie_nation['base_forms_encounters'] >= 10)\n",
    "    ]\n",
    "    values = ['1', '2', '3-4', '5-7', '8-9', '10+'] ###\n",
    "    df_movie_nation['range_encounters'] = np.select(conditions, values)\n",
    "    \n",
    "    df_statistics = df_movie_nation.groupby('range_encounters').count()\n",
    "    total = np.sum(df_statistics['base_forms_encounters'])\n",
    "    #### APPLYING ON ROOT_encounter (shouldn't be no blanks in that column)\n",
    "    df_statistics['%'] = df_statistics['base_forms_encounters'].apply(lambda x: round((int(x)/int(total))*100))\n",
    "    df_statistics.sort_values(by=['%'], ascending=False)\n",
    "    \n",
    "    df_total_word_families = pd.DataFrame(df_statistics.sum()).T.rename(index={0:'Total word families'})\n",
    "    df_statistics = df_statistics.append(df_total_word_families)\n",
    "    df_tokens = pd.DataFrame(df_movie_nation[['base_forms_encounters']].sum(), columns=['base_forms_encounters'])\n",
    "    df_tokens.rename(index={'base_forms_encounters':'Tokens'}, inplace=True)\n",
    "    df_statistics = df_statistics.append(df_tokens)\n",
    "    df_statistics = df_statistics.fillna(0)\n",
    "    return df_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What the Top 10 characters say?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_simpsons = {}\n",
    "levels = ['4', '5-14']\n",
    "for level in levels:\n",
    "    for index in df_simpsons_analysis.index.values[:10]:\n",
    "        df_character_vocabulary = get_frames([index], df_dtm, [level])\n",
    "        df_count= get_count(df_character_vocabulary)\n",
    "        dict_simpsons['index%s_lvl%s' % (index, level)] = df_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What each character repeat the most (all levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>base_forms</th>\n",
       "      <th>base_forms_encounters</th>\n",
       "      <th>lvl</th>\n",
       "      <th>raw_character_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index0</td>\n",
       "      <td>jerk</td>\n",
       "      <td>72</td>\n",
       "      <td>lvl4</td>\n",
       "      <td>Homer Simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>index0</td>\n",
       "      <td>thou</td>\n",
       "      <td>46</td>\n",
       "      <td>lvl4</td>\n",
       "      <td>Homer Simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>index0</td>\n",
       "      <td>robot</td>\n",
       "      <td>38</td>\n",
       "      <td>lvl4</td>\n",
       "      <td>Homer Simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>index0</td>\n",
       "      <td>hug</td>\n",
       "      <td>38</td>\n",
       "      <td>lvl4</td>\n",
       "      <td>Homer Simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>index0</td>\n",
       "      <td>precious</td>\n",
       "      <td>36</td>\n",
       "      <td>lvl4</td>\n",
       "      <td>Homer Simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14935</th>\n",
       "      <td>index9</td>\n",
       "      <td>freak</td>\n",
       "      <td>1</td>\n",
       "      <td>lvl5-14</td>\n",
       "      <td>Grampa Simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14936</th>\n",
       "      <td>index9</td>\n",
       "      <td>fraught</td>\n",
       "      <td>1</td>\n",
       "      <td>lvl5-14</td>\n",
       "      <td>Grampa Simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14937</th>\n",
       "      <td>index9</td>\n",
       "      <td>fragrant</td>\n",
       "      <td>1</td>\n",
       "      <td>lvl5-14</td>\n",
       "      <td>Grampa Simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14938</th>\n",
       "      <td>index9</td>\n",
       "      <td>foreclose</td>\n",
       "      <td>1</td>\n",
       "      <td>lvl5-14</td>\n",
       "      <td>Grampa Simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14939</th>\n",
       "      <td>index9</td>\n",
       "      <td>zeppelin</td>\n",
       "      <td>1</td>\n",
       "      <td>lvl5-14</td>\n",
       "      <td>Grampa Simpson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14940 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index base_forms  base_forms_encounters      lvl raw_character_text\n",
       "0      index0       jerk                     72     lvl4      Homer Simpson\n",
       "1      index0       thou                     46     lvl4      Homer Simpson\n",
       "2      index0      robot                     38     lvl4      Homer Simpson\n",
       "3      index0        hug                     38     lvl4      Homer Simpson\n",
       "4      index0   precious                     36     lvl4      Homer Simpson\n",
       "...       ...        ...                    ...      ...                ...\n",
       "14935  index9      freak                      1  lvl5-14     Grampa Simpson\n",
       "14936  index9    fraught                      1  lvl5-14     Grampa Simpson\n",
       "14937  index9   fragrant                      1  lvl5-14     Grampa Simpson\n",
       "14938  index9  foreclose                      1  lvl5-14     Grampa Simpson\n",
       "14939  index9   zeppelin                      1  lvl5-14     Grampa Simpson\n",
       "\n",
       "[14940 rows x 5 columns]"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vocabulary_simpsons = pd.concat(dict_simpsons)[['base_forms', 'base_forms_encounters']].reset_index()\n",
    "df_vocabulary_simpsons.drop('level_1', axis=1, inplace=True)\n",
    "df_vocabulary_simpsons['lvl'] = df_vocabulary_simpsons['level_0'].apply(lambda x:x.split('_')[1])\n",
    "df_vocabulary_simpsons['level_0'] = df_vocabulary_simpsons['level_0'].apply(lambda x:x.split('_')[0])\n",
    "df_vocabulary_simpsons.rename(columns={'level_0':'index'}, inplace=True)\n",
    "df_vocabulary_simpsons = pd.merge(df_vocabulary_simpsons, df_character[['index', 'raw_character_text']])\n",
    "df_vocabulary_simpsons\n",
    "# for i in df_vocabulary_simpsons.values:\n",
    "#     print(i[1]+'|'+str(i[2])+'|'+i[3]+'|'+i[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who has the highest % hard word in their lines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vocabulary_character = pd.concat([\n",
    "    df_character.set_index('raw_character_text'),\n",
    "    df_vocabulary_simpsons.groupby('raw_character_text').sum(),\n",
    "    df_simpsons_lines\n",
    "], axis=1)[['raw_text', 'tokens', 'base_forms_encounters']] #total lines, total tokens, tokens lvl4+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>base_forms_encounters</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C. Montgomery Burns</th>\n",
       "      <td>3172.0</td>\n",
       "      <td>38266</td>\n",
       "      <td>2260.0</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seymour Skinner</th>\n",
       "      <td>2443.0</td>\n",
       "      <td>29601</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Krusty the Clown</th>\n",
       "      <td>1772.0</td>\n",
       "      <td>21873</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ned Flanders</th>\n",
       "      <td>2145.0</td>\n",
       "      <td>24224</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bart Simpson</th>\n",
       "      <td>13777.0</td>\n",
       "      <td>117468</td>\n",
       "      <td>5136.0</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grampa Simpson</th>\n",
       "      <td>1886.0</td>\n",
       "      <td>21125</td>\n",
       "      <td>868.0</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lisa Simpson</th>\n",
       "      <td>11502.0</td>\n",
       "      <td>106054</td>\n",
       "      <td>4328.0</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Homer Simpson</th>\n",
       "      <td>29842.0</td>\n",
       "      <td>288596</td>\n",
       "      <td>11667.0</td>\n",
       "      <td>4.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moe Szyslak</th>\n",
       "      <td>2864.0</td>\n",
       "      <td>34627</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>4.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marge Simpson</th>\n",
       "      <td>14159.0</td>\n",
       "      <td>134192</td>\n",
       "      <td>4413.0</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     raw_text  tokens  base_forms_encounters     %\n",
       "C. Montgomery Burns    3172.0   38266                 2260.0  5.91\n",
       "Seymour Skinner        2443.0   29601                 1461.0  4.94\n",
       "Krusty the Clown       1772.0   21873                 1049.0  4.80\n",
       "Ned Flanders           2145.0   24224                 1099.0  4.54\n",
       "Bart Simpson          13777.0  117468                 5136.0  4.37\n",
       "Grampa Simpson         1886.0   21125                  868.0  4.11\n",
       "Lisa Simpson          11502.0  106054                 4328.0  4.08\n",
       "Homer Simpson         29842.0  288596                11667.0  4.04\n",
       "Moe Szyslak            2864.0   34627                 1400.0  4.04\n",
       "Marge Simpson         14159.0  134192                 4413.0  3.29"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vocabulary_character['%'] = round(100 * (df_vocabulary_character['base_forms_encounters']/\n",
    "                                                   df_vocabulary_character['tokens']), 2)\n",
    "df_vocabulary_character.sort_values('%', ascending=False)[:10]\n",
    "# for i in df_vocabulary_character.sort_values('%', ascending=False).reset_index()[:10].values:\n",
    "#     print(i[0] + ',' + f'{i[1]:.0f}'',' + f'{i[2]:.0f}'',' + f'{i[3]:.0f}'',' + f'{i[4]:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
